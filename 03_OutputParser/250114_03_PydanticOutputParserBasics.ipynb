{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# api 불러오기\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# 환경 변수 불러오기\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "LANGCHAIN_TRACING_V2 = os.getenv(\"LANGCHAIN_TRACING_V2\")\n",
    "LANGCHAIN_ENDPOINT = os.getenv(\"LANGCHAIN_ENDPOINT\")\n",
    "LANGCHAIN_PROJECT = os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_conversation = \"\"\"\n",
    "From: John (John@bikecorporation.me)\n",
    "To: Kim (Kim@teddyinternational.me)\n",
    "Subject: “ZENESIS” bike distribution cooperation and meeting schedule proposal\n",
    "Dear Mr. Kim,\n",
    "\n",
    "I am John, Senior Executive Director at Bike Corporation. I recently learned about your new bicycle model, \"ZENESIS,\" through your press release. Bike Corporation is a company that leads innovation and quality in the field of bicycle manufacturing and distribution, with long-time experience and expertise in this field.\n",
    "\n",
    "We would like to request a detailed brochure for the ZENESIS model. In particular, we need information on technical specifications, battery performance, and design aspects. This information will help us further refine our proposed distribution strategy and marketing plan.\n",
    "\n",
    "Additionally, to discuss the possibilities for collaboration in more detail, I propose a meeting next Tuesday, January 15th, at 10:00 AM. Would it be possible to meet at your office to have this discussion?\n",
    "\n",
    "Thank you.\n",
    "\n",
    "Best regards,\n",
    "John\n",
    "Senior Executive Director\n",
    "Bike Corporation\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# oupput parser 사용하지 않는경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.messages import AIMessageChunk\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from itertools import chain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"다음의 이메일 내용중 중요한 내용을 추출해 주세요.\\n\\n{email_conversation}\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "answer = chain.stream({\"email_conversation\": email_conversation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the important points from the email:\n",
      "\n",
      "1. John, Senior Executive Director at Bike Corporation, is interested in the \"ZENESIS\" bicycle model from Teddy International.\n",
      "2. He requests a detailed brochure for the ZENESIS model, focusing on technical specifications, battery performance, and design aspects.\n",
      "3. John proposes a meeting to discuss potential collaboration on Tuesday, January 15th, at 10:00 AM, at Kim's office."
     ]
    }
   ],
   "source": [
    "def stream_response(response, return_output=False):\n",
    "    \"\"\"\n",
    "    Streams the response from the AI model, processing and printing each chunk.\n",
    "\n",
    "    This function iterates over each item in the 'response' iterable. If an item is an instance of AIMessageChunk, it extracts and prints the content.\n",
    "    If the item is a string, it prints the string directly.\n",
    "    Optionally, the function can return the concatenated string of all response chunks.\n",
    "\n",
    "    Args:\n",
    "    - response (iterable): An iterable of response chunks, which can be AIMessageChunk objects or strings.\n",
    "    - return_output (bool, optional): If True, the function returns the concatenated response string. The default is False.\n",
    "\n",
    "    Returns:\n",
    "    - str: If `return_output` is True, the concatenated response string. Otherwise, nothing is returned.\n",
    "    \"\"\"\n",
    "    answer = \"\"\n",
    "    for token in response:\n",
    "        if isinstance(token, AIMessageChunk):\n",
    "            answer += token.content\n",
    "            print(token.content, end=\"\", flush=True)\n",
    "        elif isinstance(token, str):\n",
    "            answer += token\n",
    "            print(token, end=\"\", flush=True)\n",
    "    if return_output:\n",
    "        return answer\n",
    "    \n",
    "output = stream_response(answer, return_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_core in c:\\users\\eys63\\github\\jju\\.venv\\lib\\site-packages (0.3.29)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\eys63\\github\\jju\\.venv\\lib\\site-packages (from langchain_core) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\eys63\\github\\jju\\.venv\\lib\\site-packages (from langchain_core) (1.33)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.125 in c:\\users\\eys63\\github\\jju\\.venv\\lib\\site-packages (from langchain_core) (0.2.10)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\eys63\\github\\jju\\.venv\\lib\\site-packages (from langchain_core) (24.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\eys63\\github\\jju\\.venv\\lib\\site-packages (from langchain_core) (2.10.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\eys63\\github\\jju\\.venv\\lib\\site-packages (from langchain_core) (9.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\eys63\\github\\jju\\.venv\\lib\\site-packages (from langchain_core) (4.12.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\eys63\\github\\jju\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain_core) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\eys63\\github\\jju\\.venv\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain_core) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\eys63\\github\\jju\\.venv\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain_core) (3.10.14)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\eys63\\github\\jju\\.venv\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain_core) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\eys63\\github\\jju\\.venv\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain_core) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\eys63\\github\\jju\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain_core) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\eys63\\github\\jju\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain_core) (2.27.2)\n",
      "Requirement already satisfied: anyio in c:\\users\\eys63\\github\\jju\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_core) (4.8.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\eys63\\github\\jju\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_core) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\eys63\\github\\jju\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_core) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\users\\eys63\\github\\jju\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_core) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\eys63\\github\\jju\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_core) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\eys63\\github\\jju\\.venv\\lib\\site-packages (from requests<3,>=2->langsmith<0.3,>=0.1.125->langchain_core) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\eys63\\github\\jju\\.venv\\lib\\site-packages (from requests<3,>=2->langsmith<0.3,>=0.1.125->langchain_core) (2.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\eys63\\github\\jju\\.venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_core) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- **Sender:** John (Senior Executive Director at Bike Corporation)\n",
      "- **Recipient:** Kim (Teddy International)\n",
      "- **Subject:** \"ZENESIS\" bike distribution cooperation and meeting schedule proposal\n",
      "- **Key Points:**\n",
      "  - John learned about the \"ZENESIS\" bicycle model through a press release.\n",
      "  - Bike Corporation is interested in a detailed brochure for the ZENESIS model, focusing on technical specifications, battery performance, and design aspects.\n",
      "  - John proposes a meeting to discuss collaboration possibilities in more detail.\n",
      "  - Suggested meeting date and time: Next Tuesday, January 15th, at 10:00 AM, at Kim's office."
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"Please extract the important parts of the following email.\n",
    "    {email_conversation}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
    "chain = prompt | llm\n",
    "answer = chain.stream({\"email_conversation\":email_conversation})\n",
    "output = stream_response(answer, return_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmailSummary(BaseModel):\n",
    "    person: str = Field(description=\"메일을 보낸 사람\")\n",
    "    email: str = Field(description=\"메일을 보낸 사람의 이메일 주소\")\n",
    "    subject: str = Field(description=\"메일 제목\")\n",
    "    summary: str = Field(description=\"메일 본문을 요약한 텍스트\")\n",
    "    Is_Spam: str = Field(description=\"스팸 메일 여부\")\n",
    "    date: str = Field(description=\"메일 본문에 언급된 미팅 날짜와 시간\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PydanticOutputParser 생성\n",
    "parser = PydanticOutputParser(pydantic_object=EmailSummary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "You are a helpful assistant. Please answer the following questions in KOREAN.\n",
    "\n",
    "QUESTION:\n",
    "{question}\n",
    "\n",
    "EMAIL CONVERSATION:\n",
    "{email_conversation}\n",
    "\n",
    "FORMAT:\n",
    "{format}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format 에 PydanticOutputParser의 부분 포맷팅(partial) 추가\n",
    "prompt = prompt.partial(format=parser.get_format_instructions())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['email_conversation', 'question'], input_types={}, partial_variables={'format': 'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"person\": {\"description\": \"메일을 보낸 사람\", \"title\": \"Person\", \"type\": \"string\"}, \"email\": {\"description\": \"메일을 보낸 사람의 이메일 주소\", \"title\": \"Email\", \"type\": \"string\"}, \"subject\": {\"description\": \"메일 제목\", \"title\": \"Subject\", \"type\": \"string\"}, \"summary\": {\"description\": \"메일 본문을 요약한 텍스트\", \"title\": \"Summary\", \"type\": \"string\"}, \"date\": {\"description\": \"메일 본문에 언급된 미팅 날짜와 시간\", \"title\": \"Date\", \"type\": \"string\"}}, \"required\": [\"person\", \"email\", \"subject\", \"summary\", \"date\"]}\\n```'}, template='\\nYou are a helpful assistant. Please answer the following questions in KOREAN.\\n\\nQUESTION:\\n{question}\\n\\nEMAIL CONVERSATION:\\n{email_conversation}\\n\\nFORMAT:\\n{format}\\n')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain 을 생성합니다.\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain 을 실행하고 결과를 출력합니다.\n",
    "response = chain.stream(\n",
    "    {\n",
    "        \"email_conversation\": email_conversation,\n",
    "        \"question\": \"이메일 내용중 주요 내용을 추출해.\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"person\": \"John\",\n",
      "    \"email\": \"John@bikecorporation.me\",\n",
      "    \"subject\": \"“ZENESIS” bike distribution cooperation and meeting schedule proposal\",\n",
      "    \"summary\": \"John은 Bike Corporation의 고위 임원으로, Kim에게 ZENESIS 자전거 모델의 상세 브로셔를 요청하고, 협력 가능성을 논의하기 위해 1월 15일 화요일 오전 10시에 Kim의 사무실에서 회의를 제안합니다.\",\n",
      "    \"date\": \"January 15th, 10:00 AM\"\n",
      "}\n",
      "```"
     ]
    }
   ],
   "source": [
    "# 결과는 JSON 형태로 출력됩니다.\n",
    "output = stream_response(response, return_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='```json\\n{\\n    \"person\": \"John\",\\n    \"email\": \"John@bikecorporation.me\",\\n    \"subject\": \"“ZENESIS” bike distribution cooperation and meeting schedule proposal\",\\n    \"summary\": \"John은 Bike Corporation의 고위 임원으로, Kim에게 ZENESIS 자전거 모델의 상세 브로셔를 요청하며, 기술 사양, 배터리 성능, 디자인 측면에 대한 정보를 필요로 한다고 언급했다. 또한, 협력 가능성을 논의하기 위해 1월 15일 화요일 오전 10시에 Kim의 사무실에서 회의를 제안했다.\",\\n    \"date\": \"January 15th, 10:00 AM\"\\n}\\n```' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 151, 'prompt_tokens': 530, 'total_tokens': 681, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_4691090a87', 'finish_reason': 'stop', 'logprobs': None} id='run-5e0639fb-a47a-48ee-bf9f-a37d5dfbd431-0' usage_metadata={'input_tokens': 530, 'output_tokens': 151, 'total_tokens': 681, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# chain 을 실행하고 결과를 출력합니다.\n",
    "response = chain.invoke(\n",
    "    {\n",
    "        \"email_conversation\": email_conversation,\n",
    "        \"question\": \"이메일 내용중 주요 내용을 추출해 주세요.\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# 결과는 EmailSummary 객체 형태로 출력됩니다.\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AIMessage' object has no attribute 'person'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperson\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\eys63\\github\\JJU\\.venv\\Lib\\site-packages\\pydantic\\main.py:891\u001b[0m, in \u001b[0;36mBaseModel.__getattr__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    888\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[0;32m    889\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    890\u001b[0m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[1;32m--> 891\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'AIMessage' object has no attribute 'person'"
     ]
    }
   ],
   "source": [
    "response.person"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
