{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LlamaParser\n",
    "LlamaParse는 LlamaIndex에서 개발한 문서 파싱 서비스로, 대규모 언어 모델(LLM)을 위해 특별히 설계되었습니다. 주요 특징은 다음과 같습니다:\n",
    "\n",
    "PDF, Word, PowerPoint, Excel 등 다양한 문서 형식 지원  \n",
    "자연어 지시를 통한 맞춤형 출력 형식 제공  \n",
    "복잡한 표와 이미지 추출 기능  \n",
    "JSON 모드 지원  \n",
    "외국어 지원  \n",
    "\n",
    "LlamaParse는 독립형 API로 제공되며, LlamaCloud 플랫폼의 일부로도 사용 가능합니다. 이 서비스는 문서를 파싱하고 정제하여 검색 증강 생성(RAG) 등 LLM 기반 애플리케이션의 성능을 향상시키는 것을 목표로 합니다.\n",
    "\n",
    "사용자는 무료로 하루 1,000페이지를 처리할 수 있으며, 유료 플랜을 통해 추가 용량을 확보할 수 있습니다. LlamaParse는 현재 공개 베타 버전으로 제공되고 있으며, 지속적으로 기능이 확장되고 있습니다.\n",
    "\n",
    "링크: https://cloud.llamaindex.ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-core\n",
      "  Downloading llama_index_core-0.12.10.post1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting llama-parse\n",
      "  Downloading llama_parse-0.5.19-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting llama-index-readers-file\n",
      "  Downloading llama_index_readers_file-0.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\eys63\\anaconda3\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\eys63\\anaconda3\\lib\\site-packages (from llama-index-core) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\eys63\\anaconda3\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core) (2.0.30)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\eys63\\anaconda3\\lib\\site-packages (from llama-index-core) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\eys63\\anaconda3\\lib\\site-packages (from llama-index-core) (0.6.7)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core)\n",
      "  Downloading Deprecated-1.2.15-py2.py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core)\n",
      "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\eys63\\anaconda3\\lib\\site-packages (from llama-index-core) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\eys63\\anaconda3\\lib\\site-packages (from llama-index-core) (2024.3.1)\n",
      "Requirement already satisfied: httpx in c:\\users\\eys63\\anaconda3\\lib\\site-packages (from llama-index-core) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\eys63\\anaconda3\\lib\\site-packages (from llama-index-core) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\eys63\\anaconda3\\lib\\site-packages (from llama-index-core) (3.2.1)\n",
      "Collecting nltk>3.8.1 (from llama-index-core)\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\eys63\\anaconda3\\lib\\site-packages (from llama-index-core) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\eys63\\anaconda3\\lib\\site-packages (from llama-index-core) (10.3.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in c:\\users\\eys63\\anaconda3\\lib\\site-packages (from llama-index-core) (2.9.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\eys63\\anaconda3\\lib\\site-packages (from llama-index-core) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in c:\\users\\eys63\\anaconda3\\lib\\site-packages (from llama-index-core) (8.2.2)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\eys63\\anaconda3\\lib\\site-packages (from llama-index-core) (0.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\eys63\\anaconda3\\lib\\site-packages (from llama-index-core) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\eys63\\anaconda3\\lib\\site-packages (from llama-index-core) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\eys63\\anaconda3\\lib\\site-packages (from llama-index-core) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\eys63\\anaconda3\\lib\\site-packages (from llama-index-core) (1.17.0)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.7 in c:\\users\\eys63\\anaconda3\\lib\\site-packages (from llama-parse) (8.1.7)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in c:\\users\\eys63\\anaconda3\\lib\\site-packages (from llama-index-readers-file) (4.12.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\eys63\\anaconda3\\lib\\site-packages (from llama-index-readers-file) (2.2.3)\n",
      "Collecting pypdf<6.0.0,>=5.1.0 (from llama-index-readers-file)\n",
      "  Using cached pypdf-5.1.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file)\n",
      "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\eys63\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\eys63\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\eys63\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\eys63\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\eys63\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (1.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\eys63\\anaconda3\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file) (2.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\eys63\\anaconda3\\lib\\site-packages (from click<9.0.0,>=8.1.7->llama-parse) (0.4.6)\n",
      "Requirement already satisfied: joblib in c:\\users\\eys63\\anaconda3\\lib\\site-packages (from nltk>3.8.1->llama-index-core) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\eys63\\anaconda3\\lib\\site-packages (from nltk>3.8.1->llama-index-core) (2023.10.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\eys63\\anaconda3\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\eys63\\anaconda3\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\eys63\\anaconda3\\lib\\site-packages (from requests>=2.31.0->llama-index-core) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\eys63\\anaconda3\\lib\\site-packages (from requests>=2.31.0->llama-index-core) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\eys63\\anaconda3\\lib\\site-packages (from requests>=2.31.0->llama-index-core) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\eys63\\anaconda3\\lib\\site-packages (from requests>=2.31.0->llama-index-core) (2024.12.14)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\eys63\\anaconda3\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core) (3.0.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\eys63\\anaconda3\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\eys63\\anaconda3\\lib\\site-packages (from dataclasses-json->llama-index-core) (3.23.3)\n",
      "Requirement already satisfied: anyio in c:\\users\\eys63\\anaconda3\\lib\\site-packages (from httpx->llama-index-core) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\eys63\\anaconda3\\lib\\site-packages (from httpx->llama-index-core) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\eys63\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core) (0.14.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\eys63\\anaconda3\\lib\\site-packages (from pandas->llama-index-readers-file) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\eys63\\anaconda3\\lib\\site-packages (from pandas->llama-index-readers-file) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\eys63\\anaconda3\\lib\\site-packages (from pandas->llama-index-readers-file) (2023.3)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\eys63\\anaconda3\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core) (23.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\eys63\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file) (1.17.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\eys63\\anaconda3\\lib\\site-packages (from anyio->httpx->llama-index-core) (1.3.0)\n",
      "Downloading llama_index_core-0.12.10.post1-py3-none-any.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.1/1.6 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.0/1.6 MB 12.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.2/1.6 MB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.5/1.6 MB 8.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.6/1.6 MB 7.8 MB/s eta 0:00:00\n",
      "Downloading llama_parse-0.5.19-py3-none-any.whl (15 kB)\n",
      "Downloading llama_index_readers_file-0.4.2-py3-none-any.whl (38 kB)\n",
      "Downloading Deprecated-1.2.15-py2.py3-none-any.whl (9.9 kB)\n",
      "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Using cached pypdf-5.1.0-py3-none-any.whl (297 kB)\n",
      "Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Installing collected packages: striprtf, dirtyjson, pypdf, deprecated, nltk, llama-index-core, llama-parse, llama-index-readers-file\n",
      "  Attempting uninstall: pypdf\n",
      "    Found existing installation: pypdf 4.3.1\n",
      "    Uninstalling pypdf-4.3.1:\n",
      "      Successfully uninstalled pypdf-4.3.1\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.8.1\n",
      "    Uninstalling nltk-3.8.1:\n",
      "      Successfully uninstalled nltk-3.8.1\n",
      "Successfully installed deprecated-1.2.15 dirtyjson-1.0.8 llama-index-core-0.12.10.post1 llama-index-readers-file-0.4.2 llama-parse-0.5.19 nltk-3.9.1 pypdf-5.1.0 striprtf-0.0.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping C:\\Users\\eys63\\anaconda3\\Lib\\site-packages\\tensorflow_intel-2.18.0.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\eys63\\anaconda3\\Lib\\site-packages\\tensorflow_intel-2.18.0.dist-info due to invalid metadata entry 'name'\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-upstage 0.4.0 requires pypdf<5.0.0,>=4.2.0, but you have pypdf 5.1.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index-core llama-parse llama-index-readers-file python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nest_asyncio\n",
    "\n",
    "LLAMA_CLOUD_API_KEY = ''\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 751ed6ce-d02b-4a3c-bfa8-d26b07d55264\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from llama_parse import LlamaParse\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "    \n",
    "# .env 파일 로드\n",
    "load_dotenv(),\n",
    "\n",
    "# 환경 변수에서 API 키 가져오기\n",
    "LLAMA_CLOUD_API_KEY = os.getenv(\"LLAMA_CLOUD_API_KEY\")\n",
    "\n",
    "# 파서 설정\n",
    "parser = LlamaParse(\n",
    "    result_type=\"markdown\",  # \"markdown\"과 \"text\" 사용 가능\n",
    "    num_workers=8,  # worker 수 (기본값: 4)\n",
    "    verbose=True,   # 상세 정보 출력 (진행중인 내용 출력)\n",
    "    language=\"ko\",  # 언어 설정 (기본값: \"en\")\n",
    ")\n",
    "\n",
    "# SimpleDirectoryReader를 사용하여 파일 파싱\n",
    "file_extractor = {\".pdf\": parser}\n",
    "\n",
    "# LlamaParse로 파일 파싱\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_files=[r\"C:\\Users\\eys63\\Desktop\\기타활동\\2024\\겨울방학\\24Winter_Vacation\\data\\SPRI_AI_Brief_2023년12월호_F.pdf\"],\n",
    "    file_extractor=file_extractor,\n",
    ").load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 페이지 수 확인\n",
    "len(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc ID: f77e4d13-39df-458b-944a-6c6294123c32\n",
      "Text: # 인공지능 산업의 최신 동향  2023년 12월호\n",
      "============\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Document(id_='f77e4d13-39df-458b-944a-6c6294123c32', embedding=None, metadata={'file_path': 'C:\\\\Users\\\\eys63\\\\Desktop\\\\기타활동\\\\2024\\\\겨울방학\\\\24Winter_Vacation\\\\data\\\\SPRI_AI_Brief_2023년12월호_F.pdf', 'file_name': 'SPRI_AI_Brief_2023년12월호_F.pdf', 'file_type': 'application/pdf', 'file_size': 975735, 'creation_date': '2025-01-06', 'last_modified_date': '2025-01-06'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='# 인공지능 산업의 최신 동향\\n\\n2023년 12월호', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(documents[0])\n",
    "print(\"============\")\n",
    "documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LlamaIndex -> LangChain Document로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping C:\\Users\\eys63\\anaconda3\\Lib\\site-packages\\tensorflow_intel-2.18.0.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\eys63\\anaconda3\\Lib\\site-packages\\tensorflow_intel-2.18.0.dist-info due to invalid metadata entry 'name'\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랭체인 도큐먼트로 변환\n",
    "docs = [doc.to_langchain_format() for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 인공지능 산업의 최신 동향\n",
      "\n",
      "2023년 12월호\n",
      "============\n",
      "# 정책/법제\n",
      "\n",
      "# 기업/산업\n",
      "\n",
      "# 연구기술\n",
      "\n",
      "# 인력/교육\n",
      "\n",
      "# 영국AI안전성정상회의에참가한28개국,AI위험에공동대응선언\n",
      "\n",
      "영국블레츨리파크에서개최된AI안전성정상회의에참가한28개국들이AI안전보장을위한협력방안을담은블레츨리선언을발표\n",
      "\n",
      "첨단AI를개발하는국가와기업들은AI시스템에대한안전테스트계획에합의했으며,\n",
      "\n",
      "영국의AI안전연구소가전세계국가와협력해테스트를주도할예정\n",
      "\n",
      "# AI안전성정상회의참가국들,블레츨리선언통해AI안전보장을위한협력에합의\n",
      "\n",
      "2023년11월1~2일영국블레츨리파크에서열린AI안전성정상회의(AISafetySummit)에참가한28개국대표들이AI위험관리를위한‘블레츨리선언’을발표\n",
      "\n",
      "- 선언은AI안전보장을위해국가,국제기구,기업,시민사회,학계를포함한모든이해관계자의협력이중요하다고강조했으며,특히최첨단AI시스템개발기업은안전평가를비롯한적절한조치를취하여AI시스템의안전을보장할책임이있다고지적\n",
      "- 각국은AI안전보장을위해첨단AI개발기업의투명성향상,적절한평가지표와안전테스트도구개발,공공부문역량구축과과학연구개발등의분야에서협력하기로합의\n",
      "\n",
      "# 영국총리,정부주도의첨단AI시스템안전테스트계획발표\n",
      "\n",
      "리시수낙영국총리는AI안전성정상회의를마무리하며첨단AI모델에대한안전성시험계획수립과테스트수행을주도할영국AI안전연구소의출범을발표\n",
      "\n",
      "- 첨단AI모델의안전테스트는국가안보와안전,사회적피해를포함한여러잠재적유해기능에대한시험을포함하며,참석자들은정부주도의외부안전테스트에합의\n",
      "- 각국정부는테스트와기타안전연구를위한공공부문역량에투자하고,테스트결과가다른국가와관련된경우해당국가와결과를공유하며,적절한시기에공동표준개발을위해노력하기로합의\n",
      "\n",
      "참가국들은튜링상을수상한AI학자인요슈아벤지오교수가주도하는‘과학의현황(Stateof the Science)’보고서작성에도합의했으며,보고서를통해첨단AI의위험과가능성에관한기존연구를과학적으로평가하고향후AI안전연구를위한우선순위를제시할계획\n",
      "\n",
      "한국은영국정부와6개월뒤에온라인으로AI미니정상회의를공동개최하기로합의했으며,프랑스정부와는1년후대면정상회의를개최할예정\n",
      "\n",
      "출처: Gov.uk, TheBletchley Declaration by Countries Attending the AISafety Summit, 1-2 November 2023, 2023.11.01.\n",
      "\n",
      "Gov.uk, World leaders, top AI companies set out plan for safety testing of frontier as first global Safety AI Summit concludes, 2023.11.02.\n",
      "============\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'# 인공지능 산업의 최신 동향\\n\\n2023년 12월호'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(docs[0].page_content)\n",
    "print(\"============\")\n",
    "print(docs[5].page_content)\n",
    "print(\"============\")\n",
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_path': 'C:\\\\Users\\\\eys63\\\\Desktop\\\\기타활동\\\\2024\\\\겨울방학\\\\24Winter_Vacation\\\\data\\\\SPRI_AI_Brief_2023년12월호_F.pdf',\n",
       " 'file_name': 'SPRI_AI_Brief_2023년12월호_F.pdf',\n",
       " 'file_type': 'application/pdf',\n",
       " 'file_size': 975735,\n",
       " 'creation_date': '2025-01-06',\n",
       " 'last_modified_date': '2025-01-06'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# metadata 출력\n",
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultiModal Model 로 파싱\n",
    "주요 파라미터\n",
    "\n",
    "use_vendor_multimodal_model: 멀티모달 모델 사용 여부를 지정합니다. True로 설정하면 외부 벤더의 멀티모달 모델을 사용합니다.  \n",
    "\n",
    "vendor_multimodal_model_name: 사용할 멀티모달 모델의 이름을 지정합니다. 여기서는 \"openai-gpt4o\"를 사용하고 있습니다.\n",
    "\n",
    "vendor_multimodal_api_key: 멀티모달 모델 API 키를 지정합니다. 환경 변수에서 OpenAI API 키를 가져옵니다.\n",
    "\n",
    "result_type: 파싱 결과의 형식을 지정합니다. \"markdown\"으로 설정되어 있어 결과가 마크다운 형식으로 반환됩니다.\n",
    "\n",
    "language: 파싱할 문서의 언어를 지정합니다. \"ko\"로 설정되어 한국어로 처리됩니다.\n",
    "\n",
    "skip_diagonal_text: 대각선 텍스트를 건너뛸지 여부를 결정합니다.\n",
    "\n",
    "page_separator: 페이지 구분자를 지정할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from llama_parse import LlamaParse\n",
    "\n",
    "# .env 파일 로드\n",
    "load_dotenv()\n",
    "\n",
    "# LlamaParse 설정\n",
    "documents = LlamaParse(\n",
    "    use_vendor_multimodal_model=True,\n",
    "    vendor_multimodal_model_name=\"openai-gpt4o\",\n",
    "    vendor_multimodal_api_key=os.getenv(\"OPENAI_API_KEY\"),  # .env에서 API 키 로드\n",
    "    result_type=\"markdown\",\n",
    "    language=\"ko\",\n",
    "    # skip_diagonal_text=True,\n",
    "    # page_separator=\"\\n=================\\n\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
